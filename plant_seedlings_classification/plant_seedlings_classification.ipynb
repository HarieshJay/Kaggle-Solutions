{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Seedlings Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/plant-seedlings-classification/data\n",
    "\n",
    "Determine the species of a seedling from an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Checkpoint File | Training Accuracy | Validation Accuracy  | Kaggle Score | \n",
    "| :--- | :--- | :--- | :--- |\n",
    "| ./checkpoints/checkpoint_m1_1 | 0.9684 |  0.9556 | 0.95214 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/plant-seedlings-classification')\n",
    "image_count = len(list(data_dir.glob('train/*/*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4750 images belonging to 12 classes.\n",
      "Found 0 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=360,\n",
    "        validation_split=0.2)\n",
    "train_dir = '/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/plant-seedlings-classification/train'\n",
    "classes = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed',\n",
    "       'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize',\n",
    "       'Scentless Mayweed', 'Shepherds Purse',\n",
    "       'Small-flowered Cranesbill', 'Sugar beet']\n",
    "\n",
    "train_data_gen = image_generator.flow_from_directory(directory=train_dir,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = classes,\n",
    "                                                     subset=\"training\")\n",
    "\n",
    "valid_data_gen = image_generator.flow_from_directory(directory=train_dir,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = classes,\n",
    "                                                     subset=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 111, 111, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 54, 54, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4718656   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 6,278,412\n",
      "Trainable params: 6,276,492\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_v1 = keras.Sequential()\n",
    "\n",
    "model_v1.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model_v1.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model_v1.add(keras.layers.BatchNormalization())\n",
    "model_v1.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "model_v1.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_v1.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model_v1.add(keras.layers.BatchNormalization())\n",
    "model_v1.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "model_v1.add(keras.layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model_v1.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model_v1.add(keras.layers.BatchNormalization())\n",
    "model_v1.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "model_v1.add(keras.layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model_v1.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model_v1.add(keras.layers.BatchNormalization())\n",
    "model_v1.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "model_v1.add(keras.layers.Flatten())\n",
    "\n",
    "model_v1.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001)))\n",
    "model_v1.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "model_v1.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001)))\n",
    "model_v1.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "model_v1.add(keras.layers.Dense(12, activation='softmax'))\n",
    "\n",
    "model_v1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_m1_1 = './checkpoints/checkpoint_m1_1'\n",
    "checkpoint_path_m1_2 = './checkpoints/checkpoint_m1_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f28849b1d68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v1.load_weights(checkpoint_path_m1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, min_delta=1e-5, patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3, min_delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=STEPS_PER_EPOCH*1000,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "\n",
    "def get_optimizer():\n",
    "  return tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_early_training = tf.keras.optimizers.Adam(0.0001)\n",
    "optimizer_final_training = tf.keras.optimizers.SGD(0.000001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1.compile(optimizer=optimizer_final_training,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 149 steps\n",
      "Epoch 1/30\n",
      "149/149 [==============================] - 116s 777ms/step - loss: 0.2388 - accuracy: 0.9665\n",
      "Epoch 2/30\n",
      "149/149 [==============================] - 118s 791ms/step - loss: 0.2323 - accuracy: 0.9707\n",
      "Epoch 3/30\n",
      "149/149 [==============================] - 118s 792ms/step - loss: 0.2373 - accuracy: 0.9678\n",
      "Epoch 4/30\n",
      "149/149 [==============================] - 117s 787ms/step - loss: 0.2364 - accuracy: 0.9709\n",
      "Epoch 5/30\n",
      "149/149 [==============================] - 118s 791ms/step - loss: 0.2304 - accuracy: 0.9680\n",
      "Epoch 6/30\n",
      "149/149 [==============================] - 118s 791ms/step - loss: 0.2297 - accuracy: 0.9714\n",
      "Epoch 7/30\n",
      "149/149 [==============================] - 118s 793ms/step - loss: 0.2320 - accuracy: 0.9697\n",
      "Epoch 8/30\n",
      "149/149 [==============================] - 118s 794ms/step - loss: 0.2253 - accuracy: 0.9709\n",
      "Epoch 9/30\n",
      "149/149 [==============================] - 118s 790ms/step - loss: 0.2440 - accuracy: 0.9699\n",
      "Epoch 10/30\n",
      "149/149 [==============================] - 117s 788ms/step - loss: 0.2354 - accuracy: 0.9682\n",
      "Epoch 11/30\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9695\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "149/149 [==============================] - 117s 788ms/step - loss: 0.2297 - accuracy: 0.9693\n",
      "Epoch 12/30\n",
      "149/149 [==============================] - 118s 791ms/step - loss: 0.2401 - accuracy: 0.9693\n",
      "Epoch 13/30\n",
      "149/149 [==============================] - 117s 782ms/step - loss: 0.2354 - accuracy: 0.9665\n",
      "Epoch 14/30\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 0.9659\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "149/149 [==============================] - 119s 796ms/step - loss: 0.2371 - accuracy: 0.9661\n",
      "Epoch 15/30\n",
      "149/149 [==============================] - 118s 792ms/step - loss: 0.2463 - accuracy: 0.9659\n",
      "Epoch 16/30\n",
      "149/149 [==============================] - 119s 795ms/step - loss: 0.2385 - accuracy: 0.9709\n",
      "Epoch 17/30\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2261 - accuracy: 0.9695\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "149/149 [==============================] - 131s 878ms/step - loss: 0.2256 - accuracy: 0.9697\n",
      "Epoch 18/30\n",
      "149/149 [==============================] - 118s 789ms/step - loss: 0.2327 - accuracy: 0.9695\n",
      "Epoch 19/30\n",
      "149/149 [==============================] - 118s 791ms/step - loss: 0.2355 - accuracy: 0.9659\n",
      "Epoch 20/30\n",
      "149/149 [==============================] - 118s 790ms/step - loss: 0.2200 - accuracy: 0.9737\n",
      "Epoch 21/30\n",
      "149/149 [==============================] - 117s 788ms/step - loss: 0.2272 - accuracy: 0.9712\n",
      "Epoch 22/30\n",
      "149/149 [==============================] - 118s 792ms/step - loss: 0.2334 - accuracy: 0.9667\n",
      "Epoch 23/30\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9669\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "149/149 [==============================] - 118s 792ms/step - loss: 0.2377 - accuracy: 0.9667\n",
      "Epoch 24/30\n",
      "149/149 [==============================] - 119s 797ms/step - loss: 0.2391 - accuracy: 0.9665\n",
      "Epoch 25/30\n",
      "149/149 [==============================] - 118s 793ms/step - loss: 0.2293 - accuracy: 0.9686\n",
      "Epoch 26/30\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2438 - accuracy: 0.9701\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "149/149 [==============================] - 118s 793ms/step - loss: 0.2441 - accuracy: 0.9699\n",
      "Epoch 27/30\n",
      "149/149 [==============================] - 118s 794ms/step - loss: 0.2259 - accuracy: 0.9735\n",
      "Epoch 28/30\n",
      "149/149 [==============================] - 118s 794ms/step - loss: 0.2376 - accuracy: 0.9663\n",
      "Epoch 29/30\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.2316 - accuracy: 0.9663\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "149/149 [==============================] - 118s 792ms/step - loss: 0.2315 - accuracy: 0.9663\n",
      "Epoch 30/30\n",
      "149/149 [==============================] - 118s 791ms/step - loss: 0.2335 - accuracy: 0.9684\n"
     ]
    }
   ],
   "source": [
    "model_v1_history = model_v1.fit(train_data_gen, epochs=30, steps_per_epoch=None, validation_data=valid_data_gen, callbacks=[lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1.save_weights(checkpoint_path_m1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Predicting with Convolutional Neural Net 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 794 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/plant-seedlings-classification/'\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = image_generator.flow_from_directory(directory=test_dir,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=False,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = ['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_v1.predict(\n",
    "    test_data_gen, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,\n",
    "    workers=1, use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = [classes[i] for i in y]\n",
    "files = [path[5:] for path in test_data_gen.filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = np.stack([files,predicted_classes], axis=1)\n",
    "np.savetxt('submission.csv', subm, fmt='%s,%s', header='file,species', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Analysis of Convolutional Neural Net 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(0, len(model_v1_history.history['loss']))\n",
    "training_loss = model_v1_history.history['loss']\n",
    "validation_loss = model_v1_history.history['val_loss']\n",
    "\n",
    "# training loss \n",
    "plt.plot(epochs, training_loss)\n",
    "plt.xlabel(\"Number of epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()\n",
    "\n",
    "# validation loss\n",
    "plt.plot(epochs , validation_loss)\n",
    "plt.xlabel(\"Number of epoch\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
