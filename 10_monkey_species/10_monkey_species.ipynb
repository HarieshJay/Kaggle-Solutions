{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Monkey Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/slothkong/10-monkey-species?\n",
    "\n",
    "Fine-grain classification with 10 species of monkeys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9'],\n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path('/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/10-monkey-species')\n",
    "image_count = len(list(data_dir.glob('*/*/*/*.jpg')))\n",
    "CLASS_NAMES = np.sort(np.array([item.name for item in data_dir.glob('training/training/*')]), axis=0)\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_map = [ \"alouattapalliata\", \"erythrocebuspatas\", \"cacajaocalvus\", \"macacafuscata\", \"cebuellapygmea\", \"cebuscapucinus\",\n",
    "                \"micoargentatus\", \"saimirisciureus\", \"aotusnigriceps\", \"trachypithecusjohnii\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/10-monkey-species/training/training/n0/n0029.jpg'\n",
      "b'/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/10-monkey-species/training/training/n3/n3037.jpg'\n",
      "b'/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/10-monkey-species/training/training/n0/n0051.jpg'\n",
      "b'/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/10-monkey-species/training/training/n5/n5025.jpg'\n",
      "b'/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/10-monkey-species/training/training/n1/n1021.jpg'\n"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'training/training/*/*'))\n",
    "for f in list_ds.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=103, shape=(10,), dtype=bool, numpy=\n",
       "array([False, False, False, False, False, False, False,  True, False,\n",
       "       False])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == CLASS_NAMES\n",
    "\n",
    "get_label('/notebooks/storage/kaggle-solutions/Kaggle-Solutions/data/10-monkey-species/training/training/n7/n7054.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (224, 224, 3)\n",
      "Label:  [ True False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "for image, label in labeled_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "      ds = ds.cache(cache)\n",
    "    else:\n",
    "      ds = ds.cache()\n",
    "\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "  # Repeat forever\n",
    "  ds = ds.repeat()\n",
    "\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(labeled_ds)\n",
    "image_batch, label_batch = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((None, 224, 224, 3), (None, 10)), types: (tf.float32, tf.bool)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.batch(BATCH_SIZE)\n",
    "train_ds.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for n in range(25):\n",
    "      ax = plt.subplot(5,5,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "      plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(image_batch.numpy(), label_batch.numpy())\n",
    "print(label_batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 173056)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                11075648  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 11,132,618\n",
      "Trainable params: 11,132,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_v1 = keras.Sequential()\n",
    "model_v1.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model_v1.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model_v1.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_v1.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model_v1.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_v1.add(keras.layers.Flatten())\n",
    "model_v1.add(keras.layers.Dense(64, activation='relu'))\n",
    "model_v1.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model_v1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 43.0 steps\n",
      "Epoch 1/7\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.4074 - accuracy: 0.5262\n",
      "Epoch 2/7\n",
      "43/43 [==============================] - 2s 53ms/step - loss: 0.8203 - accuracy: 0.7311\n",
      "Epoch 3/7\n",
      "43/43 [==============================] - 2s 54ms/step - loss: 0.4007 - accuracy: 0.8815\n",
      "Epoch 4/7\n",
      "43/43 [==============================] - 2s 54ms/step - loss: 0.1147 - accuracy: 0.9651\n",
      "Epoch 5/7\n",
      "43/43 [==============================] - 2s 54ms/step - loss: 0.0282 - accuracy: 0.9942\n",
      "Epoch 6/7\n",
      "43/43 [==============================] - 2s 54ms/step - loss: 0.0108 - accuracy: 0.9978\n",
      "Epoch 7/7\n",
      "43/43 [==============================] - 2s 54ms/step - loss: 0.0089 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09702d12b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v1.fit(train_ds, epochs=7, steps_per_epoch=STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on a Friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "friend = tf.keras.utils.get_file('image.jpg','url excluded for privacy reasons')\n",
    "friend = Image.open(yathu).resize(IMAGE_SHAPE)\n",
    "friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend = np.array(friend)/255.0\n",
    "result = model_v1.predict(friend[np.newaxis, ...])\n",
    "predicted_class = np.argmax(result[0], axis=-1)\n",
    "monkey = monkey_map[predicted_class]\n",
    "confidence = result[0][5] * 100\n",
    "txt = \"Predicted {} with a confidence of {}%.\"\n",
    "print(txt.format(monkey, confidence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
